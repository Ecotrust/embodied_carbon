{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Timber Output Data from a Web Tool\n",
    "\n",
    "In this notebook, we will scrape some data from the [Timber Products Output (TPO) Reporting Tool](https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_rpa_int1.php) produced by the US Forest Service. \n",
    "\n",
    "The TPO reporting tool contains two primary data sources: TPO and RPA.\n",
    "\n",
    "* **TPO:** Most US States collect data for state-level Timber Products Output (TPO) reports every 2-5 years. The years available are unique for each state, but are often collected and released more frequent than the regional or national reports.\n",
    "\n",
    "* **RPA:** Since 1997, regional and national reports are produced covering all states in a region or across the USA every five years. This reporting is mandated by the Resource Protection Act (RPA), and these reports are known as RPA reports. The TPO Reporting Tool contains RPA data up until 2012 (2017 data are not yet integrated into the tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `requests` Python library to start a `session` to keep track of things like cookies and headers that will be sent and received to/from the TPO Reporting Tool.\n",
    "\n",
    "This example focuses on extracting data from a custom table generated by the TPO Reporting Tool that display the output of industrial roundwood by each owner type (e.g., State & Local, Federal, Private) in each county. Each table will includes data for one state from one year. It is definitely possible to generalize and modify this code to query multiple states and regions or request other data tables, but we will focus here on a more limited use case of just scraping the data we need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a FIPS lookup table\n",
    "The TPO reporting tool identifies states using Federal Information Processing Standard (FIPS) codes. We'll grab a list of these codes and create a lookup table to help identify which states we're working with and allow requests to be made using the 2-letter alphabetical codes for a state (e.g., AL, OR, TX, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE_NAME</th>\n",
       "      <th>FIPS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALPHA_CODE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AK</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>California</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATE_NAME FIPS\n",
       "ALPHA_CODE                 \n",
       "AL             Alabama   01\n",
       "AK              Alaska   02\n",
       "AZ             Arizona   04\n",
       "AR            Arkansas   05\n",
       "CA          California   06"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIPS_URL ='https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code'\n",
    "state_fips = pd.read_html(FIPS_URL, header=0)[0].rename({\n",
    "    'Name': 'STATE_NAME', 'Alpha code': 'ALPHA_CODE', 'Numeric code': 'FIPS'\n",
    "}, axis=1).dropna()\n",
    "state_fips = state_fips.loc[state_fips.Status.str.contains('State;')].drop('Status', axis=1)\n",
    "state_fips['FIPS'] = state_fips['FIPS'].apply(lambda x: '{:02d}'.format(x))\n",
    "lookup_fips_by_state = state_fips.set_index('ALPHA_CODE')\n",
    "lookup_state_by_fips = state_fips.set_index('FIPS')\n",
    "lookup_fips_by_state.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a TPO lookup table\n",
    "TPO reports are released in different years for each state and based on different data-collection years as well. We need to identify which report year and which data year in our requests to the TPO Reporting Tool. To help us with this, I've scraped all the different report-year and data-year pairs for each State as a text file we'll use here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>REPORT_YEAR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th>DATA_YEAR</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AL</th>\n",
       "      <th>2015</th>\n",
       "      <td>01</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>01</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>01</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>01</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                FIPS  REPORT_YEAR\n",
       "STATE DATA_YEAR                  \n",
       "AL    2015        01         2015\n",
       "      2013        01         2013\n",
       "      2011        01         2011\n",
       "      2009        01         2009\n",
       "      2007        01         2007"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is a text file that contains all years for which TPO data are available for each state\n",
    "tpo_reports = pd.read_csv('C:/GitHub/embodied_carbon/src/tpo_data.csv')\n",
    "\n",
    "# we format it a bit to help with queries\n",
    "tpo_reports['FIPS'] = tpo_reports['FIPS'].apply(lambda x: '{:02d}'.format(x))\n",
    "tpo_reports['REPORT_YEAR'] = tpo_reports['REPORT_YEAR'].apply(lambda x: None if x == 'None' else int(x)).astype('Int64')\n",
    "tpo_reports['DATA_YEAR'] = tpo_reports['DATA_YEAR'].apply(lambda x: None if x == 'None' else int(x)).astype('Int64')\n",
    "# some states don't have any TPO reports, let's drop them\n",
    "tpo_reports = tpo_reports.dropna()\n",
    "tpo_reports['DATA_YEAR'] = tpo_reports['DATA_YEAR'].astype(str)\n",
    "\n",
    "# some states also have the same year's TPO data in multiple subsequent annual reports\n",
    "# here we will drop those rows which have the same data_year as an earlier year\n",
    "tpo_reports = tpo_reports.drop_duplicates(subset=['STATE', 'DATA_YEAR'], keep='last').reset_index(drop=True)\n",
    "tpo_reports = tpo_reports.set_index(['STATE', 'DATA_YEAR'])\n",
    "tpo_reports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data-fetching functions for TPO and RPA data\n",
    "Interacting with the TPO Reporting Tool generally follows three steps:  \n",
    "\n",
    "1. **Define data source as TPO or RPA**  \n",
    "Both reports contain comparable data and provide the same output table formats.  \n",
    "\n",
    "2. **Define the US States and years to retrieve data**  \n",
    "One or more years and one or more States can be requested  \n",
    "\n",
    "3. **Select the table to view**  \n",
    "We will retrieve the table and read it into a pandas DataFrame  \n",
    "\n",
    "We will use three functions to extract TPO and RPA data. The:\n",
    "* `fetch_rpa_by_county` will retrieve RPA data as an html table for a single state and year.\n",
    "* `fetch_tpo_by_county` will retrieve TPO data as an html table for a single state and year.\n",
    "* `parse_custom_table_html` parses the html table returned by the two fetching functions, and returns a nicely-formatted Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_rpa_by_county(state_alpha_code, year):\n",
    "    # We will GET the landing page so that we can receive a SESSION ID cookie\n",
    "    START_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_rpa_int1.php'\n",
    "    # We will POST to the next URL to define the type of data requested (TPO or RPA)\n",
    "    STEP1_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_rpa_int2.php'\n",
    "    # We will POST to the next URL to define the US State and Year(s) for which we want data\n",
    "    STEP2_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_rpa_int4_public.php' # POST states and years\n",
    "    # We will GET the next URL to retrieve a table that \n",
    "    TABLE_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_table_custom_vol_roundwood_by_product_int.php' # GET table output with query params\n",
    "\n",
    "    PAYLOAD_1 = {\n",
    "        'tpo_type': 'NAT',\n",
    "        'submit1': 'Continue'\n",
    "    }\n",
    "    \n",
    "    PAYLOAD_2 = {\n",
    "        'units': '1000',\n",
    "        'show_query': '0',\n",
    "        'row1': 'CO',\n",
    "        'col1': 'OWN',\n",
    "        'tpo_or_rpa': 'RPA',\n",
    "        'submit1': 'Continue',\n",
    "    }    \n",
    "    \n",
    "    QUERY_PARAMS = {\n",
    "        'rpatpo': 'FS_SRS_FIA_RPA_TPO.rpa_tpo_1997_2002_2007_state',\n",
    "        'state_abbr_include': None,\n",
    "        'tpo_or_rpa': 'RPA',\n",
    "        'units': 1000,\n",
    "        'row1': 'CO',\n",
    "        'col1': 'OWN',\n",
    "        'show_query': 0,\n",
    "    }\n",
    "    \n",
    "    # lookup the fips code for this state\n",
    "    fips_code = lookup_fips_by_state.loc[state_alpha_code]['FIPS']\n",
    "    \n",
    "    # form fields filled out for the state and year we want\n",
    "    update_payload_2 = {\n",
    "        f'Sta_{fips_code}': 'All',\n",
    "        f'Sty_{fips_code}': year,\n",
    "        'yr1': year,\n",
    "    }\n",
    "    payload_2 = dict(PAYLOAD_2, **update_payload_2)    \n",
    "    \n",
    "    update_query_params = {\n",
    "        'state_abbr_include': state_alpha_code,\n",
    "        'yr1': year,\n",
    "    }\n",
    "    query_params = dict(QUERY_PARAMS, **update_query_params)\n",
    "    \n",
    "    with requests.session() as s:\n",
    "        s.get(START_URL)\n",
    "        s.post(STEP1_URL, data=PAYLOAD_1)\n",
    "        s.post(STEP2_URL, data=payload_2)\n",
    "        response = s.get(TABLE_URL, params=query_params)\n",
    "    \n",
    "    df = parse_custom_table_html(response.content, state_alpha_code, year)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_tpo_by_county(state_alpha_code, data_year):\n",
    "    # We will GET the landing page so that we can receive a SESSION ID cookie\n",
    "    START_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_rpa_int1.php'\n",
    "    # We will POST to the next URL to define the type of data requested (TPO or RPA)\n",
    "    STEP1_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_rpa_int2.php'\n",
    "    # We will POST to the next URL to define the US State and Year(s) for which we want data\n",
    "    STEP2_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_rpa_int4_public.php' # POST states and years\n",
    "    # We will GET the next URL to retrieve a table that \n",
    "    TABLE_URL = 'https://www.fs.usda.gov/srsfia/php/tpo_2009/tpo_table_custom_vol_roundwood_by_product_int.php' # GET table output with query params\n",
    "\n",
    "    PAYLOAD_1 = {\n",
    "        'tpo_type': 'TPO',\n",
    "        'submit1': 'Continue'\n",
    "    }\n",
    "    \n",
    "    PAYLOAD_2 = {\n",
    "        'units': '1000',\n",
    "        'show_query': '0',\n",
    "        'row1': 'CO',\n",
    "        'col1': 'OWN',\n",
    "        'tpo_or_rpa': 'TPO',\n",
    "        'submit1': 'Continue',\n",
    "    }    \n",
    "    \n",
    "    QUERY_PARAMS = {\n",
    "        'rpatpo': 'FS_SRS_FIA_RPA_TPO.srstpo_state',\n",
    "        'tpo_or_rpa': 'TPO',\n",
    "        'units': 1000,\n",
    "        'row1': 'CO',\n",
    "        'col1': 'OWN',\n",
    "        'show_query': 0,\n",
    "    }\n",
    "\n",
    "    # lookup the available data years for this state\n",
    "    try:\n",
    "        fips_code, rept_yr = tpo_reports.loc[state_alpha_code, str(data_year)]\n",
    "    except KeyError:\n",
    "        avail_values = np.sort(tpo_reports.loc[state_alpha_code].\n",
    "                               index.get_level_values(-1).values.astype(int))\n",
    "        msg = ' '.join([f'{data_year} not available for {state_alpha_code}.',\n",
    "                       f'Try one of {avail_values}.'])\n",
    "        raise KeyError(msg)\n",
    "    \n",
    "    # form fields filled out for the state and year we want\n",
    "    update_payload_2 = {\n",
    "        f'Sta_{fips_code}': 'All',\n",
    "        f'Sty_{fips_code}': f'{rept_yr} Report year ({data_year} data)',\n",
    "        'yr1': rept_yr,\n",
    "    }\n",
    "    payload_2 = dict(PAYLOAD_2, **update_payload_2)    \n",
    "    \n",
    "    update_query_params = {\n",
    "        'state_abbr_include': state_alpha_code,\n",
    "        'yr1': rept_yr,\n",
    "        'yr1_hdr': rept_yr,\n",
    "    }\n",
    "    query_params = dict(QUERY_PARAMS, **update_query_params)\n",
    "    \n",
    "    with requests.session() as s:\n",
    "        s.get(START_URL)\n",
    "        s.post(STEP1_URL, data=PAYLOAD_1)\n",
    "        s.post(STEP2_URL, data=payload_2)\n",
    "        response = s.get(TABLE_URL, params=query_params)\n",
    "    \n",
    "    df = parse_custom_table_html(response.content, state_alpha_code, data_year,\n",
    "                                addl_fields={'REPORT_YEAR': rept_yr})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_custom_table_html(html, state_alpha_code, year, addl_fields=None):\n",
    "    df = pd.read_html(html, \n",
    "                      skiprows = [0,2], \n",
    "                      header=0\n",
    "                     )[0].iloc[:-2]\n",
    "    df.insert(0, 'STATE', state_alpha_code)\n",
    "    df.insert(1, 'STATE_FIPS', \n",
    "              df['ST/CO'].apply(lambda x: '{:02d}'.format(int(x.split(',')[0]))))\n",
    "    df.insert(2, 'YEAR', year)\n",
    "    df.insert(3, 'COUNTY', \n",
    "              df['ST/CO'].apply(lambda x: x.split(',')[-1]))\n",
    "    if addl_fields is not None:\n",
    "        i = 4\n",
    "        for key, value in addl_fields.items():\n",
    "            df.insert(i, key, value)\n",
    "            i+=1\n",
    "            \n",
    "    DATA_COLS = [\n",
    "        'OWN', 'SW_10 Sawlogs', 'HW_10 Sawlogs', 'SW_20 Veneer', 'HW_20 Veneer', \n",
    "        'SW_30 Pulpwood', 'HW_30 Pulpwood', 'SW_40 Composite', 'HW_40 Composite',\n",
    "        'SW_50 Fuelwood', 'HW_50 Fuelwood', 'SW_60 Posts Poles Pilings',\n",
    "        'HW_60 Posts Poles Pilings', 'SW_90 Other', 'HW_90 Other',\n",
    "        'SW All Products', 'HW All Products', 'All Products',\n",
    "    ]\n",
    "    df[DATA_COLS] = df[DATA_COLS].astype(int)\n",
    "    df = df.drop(['ST/CO'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data for every US State\n",
    "Now, we'll scrape the TPO and RPA tables for every US State and year we can get our hands on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with Alabama.\n",
      "Done with Alaska.\n",
      "Done with Arizona.\n",
      "Done with Arkansas.\n",
      "Done with California.\n",
      "Done with Colorado.\n",
      "Done with Connecticut.\n",
      "Done with Delaware.\n",
      "Done with Florida.\n",
      "Done with Georgia.\n",
      "Done with Hawaii.\n",
      "Done with Idaho.\n",
      "Done with Illinois.\n",
      "Done with Indiana.\n",
      "Done with Iowa.\n",
      "Done with Kansas.\n",
      "Done with Kentucky.\n",
      "Done with Louisiana.\n",
      "Done with Maine.\n",
      "Done with Maryland.\n",
      "Done with Massachusetts.\n",
      "Done with Michigan.\n",
      "Done with Minnesota.\n",
      "Done with Mississippi.\n",
      "Done with Missouri.\n",
      "Done with Montana.\n",
      "Done with Nebraska.\n",
      "Done with Nevada.\n",
      "Done with New Hampshire.\n",
      "Done with New Jersey.\n",
      "Done with New Mexico.\n",
      "Done with New York.\n",
      "Done with North Carolina.\n",
      "Done with North Dakota.\n",
      "Done with Ohio.\n",
      "Done with Oklahoma.\n",
      "Done with Oregon.\n",
      "Done with Pennsylvania.\n",
      "Done with Rhode Island.\n",
      "Done with South Carolina.\n",
      "Done with South Dakota.\n",
      "Done with Tennessee.\n",
      "Done with Texas.\n",
      "Done with Utah.\n",
      "Done with Vermont.\n",
      "Done with Virginia.\n",
      "Done with Washington.\n",
      "Done with West Virginia.\n",
      "Done with Wisconsin.\n",
      "Done with Wyoming.\n"
     ]
    }
   ],
   "source": [
    "rpa_dfs = []\n",
    "for state in pd.unique(lookup_fips_by_state.index):\n",
    "    state_name = lookup_fips_by_state.loc[state]['STATE_NAME']\n",
    "    for year in [1997,2002,2007,2012]:\n",
    "        try:\n",
    "            rpa_df = fetch_rpa_by_county(state, year)\n",
    "            rpa_dfs.append(rpa_df)\n",
    "        except:\n",
    "            print(state, year)\n",
    "    print(f'Done with {state_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Alabama. Done. Fetched 10 years of data.\n",
      "Starting Alaska. Done. Fetched 5 years of data.\n",
      "Starting Arizona. Done. Fetched 6 years of data.\n",
      "Starting Arkansas. Done. Fetched 9 years of data.\n",
      "Starting California. Done. Fetched 5 years of data.\n",
      "Starting Colorado. Done. Fetched 5 years of data.\n",
      "Starting Florida. Done. Fetched 10 years of data.\n",
      "Starting Georgia. Done. Fetched 11 years of data.\n",
      "Starting Idaho. Done. Fetched 5 years of data.\n",
      "Starting Kentucky. Done. Fetched 11 years of data.\n",
      "Starting Louisiana. Done. Fetched 9 years of data.\n",
      "Starting Mississippi. Done. Fetched 9 years of data.\n",
      "Starting Montana. Done. Fetched 6 years of data.\n",
      "Starting Nevada. Done. Fetched 6 years of data.\n",
      "Starting New Mexico. Done. Fetched 6 years of data.\n",
      "Starting North Carolina. Done. Fetched 11 years of data.\n",
      "Starting Oklahoma. Done. Fetched 8 years of data.\n",
      "Starting Oregon. Done. Fetched 5 years of data.\n",
      "Starting South Carolina. Done. Fetched 11 years of data.\n",
      "Starting Tennessee. Done. Fetched 10 years of data.\n",
      "Starting Texas. Done. Fetched 11 years of data.\n",
      "Starting Utah. Done. Fetched 5 years of data.\n",
      "Starting Virginia. Done. Fetched 10 years of data.\n",
      "Starting Washington. Done. Fetched 6 years of data.\n",
      "Starting Wyoming. Done. Fetched 6 years of data.\n"
     ]
    }
   ],
   "source": [
    "tpo_dfs = []\n",
    "for state in pd.unique(tpo_reports.index.get_level_values(0)):\n",
    "    state_name = lookup_fips_by_state.loc[state]['STATE_NAME']\n",
    "    print(f'Starting {state_name}.', end=' ')\n",
    "    \n",
    "    num_yrs = 0\n",
    "    for year in tpo_reports.loc[state].index:\n",
    "        try:\n",
    "            tpo_df = fetch_tpo_by_county(state, year)\n",
    "            tpo_dfs.append(tpo_df)\n",
    "            num_yrs += 1\n",
    "        except:\n",
    "            print(state, year)\n",
    "            \n",
    "    print(f'Done. Fetched {num_yrs} years of data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all the data tables, and write to disk\n",
    "We'll make two large DataFrames for all the TPO data and all the RPA data, then write them to disk as text files which we'll use later on this research project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19623 entries, 0 to 46\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   STATE                      19623 non-null  object\n",
      " 1   STATE_FIPS                 19623 non-null  object\n",
      " 2   YEAR                       19623 non-null  object\n",
      " 3   COUNTY                     19623 non-null  object\n",
      " 4   REPORT_YEAR                19623 non-null  int64 \n",
      " 5   OWN                        19623 non-null  int32 \n",
      " 6   SW_10 Sawlogs              19623 non-null  int32 \n",
      " 7   HW_10 Sawlogs              19623 non-null  int32 \n",
      " 8   SW_20 Veneer               19623 non-null  int32 \n",
      " 9   HW_20 Veneer               19623 non-null  int32 \n",
      " 10  SW_30 Pulpwood             19623 non-null  int32 \n",
      " 11  HW_30 Pulpwood             19623 non-null  int32 \n",
      " 12  SW_40 Composite            19623 non-null  int32 \n",
      " 13  HW_40 Composite            19623 non-null  int32 \n",
      " 14  SW_50 Fuelwood             19623 non-null  int32 \n",
      " 15  HW_50 Fuelwood             19623 non-null  int32 \n",
      " 16  SW_60 Posts Poles Pilings  19623 non-null  int32 \n",
      " 17  HW_60 Posts Poles Pilings  19623 non-null  int32 \n",
      " 18  SW_90 Other                19623 non-null  int32 \n",
      " 19  HW_90 Other                19623 non-null  int32 \n",
      " 20  SW All Products            19623 non-null  int32 \n",
      " 21  HW All Products            19623 non-null  int32 \n",
      " 22  All Products               19623 non-null  int32 \n",
      "dtypes: int32(18), int64(1), object(4)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "tpo_data = pd.concat(tpo_dfs, axis=0)\n",
    "tpo_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>REPORT_YEAR</th>\n",
       "      <th>OWN</th>\n",
       "      <th>SW_10 Sawlogs</th>\n",
       "      <th>HW_10 Sawlogs</th>\n",
       "      <th>SW_20 Veneer</th>\n",
       "      <th>HW_20 Veneer</th>\n",
       "      <th>...</th>\n",
       "      <th>HW_40 Composite</th>\n",
       "      <th>SW_50 Fuelwood</th>\n",
       "      <th>HW_50 Fuelwood</th>\n",
       "      <th>SW_60 Posts Poles Pilings</th>\n",
       "      <th>HW_60 Posts Poles Pilings</th>\n",
       "      <th>SW_90 Other</th>\n",
       "      <th>HW_90 Other</th>\n",
       "      <th>SW All Products</th>\n",
       "      <th>HW All Products</th>\n",
       "      <th>All Products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>100</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>1110</td>\n",
       "      <td>86</td>\n",
       "      <td>354</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11655</td>\n",
       "      <td>4052</td>\n",
       "      <td>15706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>887</td>\n",
       "      <td>105</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>01</td>\n",
       "      <td>2015</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>2462</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16718</td>\n",
       "      <td>1973</td>\n",
       "      <td>18691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STATE STATE_FIPS  YEAR   COUNTY  REPORT_YEAR  OWN  SW_10 Sawlogs  \\\n",
       "0    AL         01  2015  Autauga         2015    2             27   \n",
       "1    AL         01  2015  Autauga         2015    4           1110   \n",
       "2    AL         01  2015  Baldwin         2015    1              0   \n",
       "3    AL         01  2015  Baldwin         2015    2            131   \n",
       "4    AL         01  2015  Baldwin         2015    4           2462   \n",
       "\n",
       "   HW_10 Sawlogs  SW_20 Veneer  HW_20 Veneer  ...  HW_40 Composite  \\\n",
       "0              2             9             0  ...                0   \n",
       "1             86           354            14  ...                0   \n",
       "2              0             0             0  ...                0   \n",
       "3              6             0            14  ...                0   \n",
       "4            117             0           272  ...                0   \n",
       "\n",
       "   SW_50 Fuelwood  HW_50 Fuelwood  SW_60 Posts Poles Pilings  \\\n",
       "0               0               0                          1   \n",
       "1               0               0                         37   \n",
       "2               0               0                          0   \n",
       "3               0               0                         33   \n",
       "4               0               0                        628   \n",
       "\n",
       "   HW_60 Posts Poles Pilings  SW_90 Other  HW_90 Other  SW All Products  \\\n",
       "0                          0            0            0              288   \n",
       "1                          0            0            0            11655   \n",
       "2                          0            0            0                2   \n",
       "3                          0            0            0              887   \n",
       "4                          0            0            0            16718   \n",
       "\n",
       "   HW All Products  All Products  \n",
       "0              100           388  \n",
       "1             4052         15706  \n",
       "2                0             2  \n",
       "3              105           992  \n",
       "4             1973         18691  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpo_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpo_data.to_csv('../data/interim/tpo_data_by_county.csv', \n",
    "                index=False, header=True,\n",
    "                quoting = csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15213 entries, 0 to 34\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   STATE                      15213 non-null  object\n",
      " 1   STATE_FIPS                 15213 non-null  object\n",
      " 2   YEAR                       15213 non-null  int64 \n",
      " 3   COUNTY                     15213 non-null  object\n",
      " 4   OWN                        15213 non-null  int32 \n",
      " 5   SW_10 Sawlogs              15213 non-null  int32 \n",
      " 6   HW_10 Sawlogs              15213 non-null  int32 \n",
      " 7   SW_20 Veneer               15213 non-null  int32 \n",
      " 8   HW_20 Veneer               15213 non-null  int32 \n",
      " 9   SW_30 Pulpwood             15213 non-null  int32 \n",
      " 10  HW_30 Pulpwood             15213 non-null  int32 \n",
      " 11  SW_40 Composite            15213 non-null  int32 \n",
      " 12  HW_40 Composite            15213 non-null  int32 \n",
      " 13  SW_50 Fuelwood             15213 non-null  int32 \n",
      " 14  HW_50 Fuelwood             15213 non-null  int32 \n",
      " 15  SW_60 Posts Poles Pilings  15213 non-null  int32 \n",
      " 16  HW_60 Posts Poles Pilings  15213 non-null  int32 \n",
      " 17  SW_90 Other                15213 non-null  int32 \n",
      " 18  HW_90 Other                15213 non-null  int32 \n",
      " 19  SW All Products            15213 non-null  int32 \n",
      " 20  HW All Products            15213 non-null  int32 \n",
      " 21  All Products               15213 non-null  int32 \n",
      "dtypes: int32(18), int64(1), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "rpa_data = pd.concat(rpa_dfs, axis=0)\n",
    "rpa_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpa_data.to_csv('../data/interim/rpa_data_by_county.csv', \n",
    "                index=False, header=True,\n",
    "                quoting = csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stand_mapping]",
   "language": "python",
   "name": "conda-env-stand_mapping-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
